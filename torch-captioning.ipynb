{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  8 19:57:26 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.66       Driver Version: 450.66       CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 2070    Off  | 00000000:26:00.0  On |                  N/A |\r\n",
      "| 31%   35C    P5    36W / 215W |    950MiB /  7979MiB |      3%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1107      G   ...-xorg-server-1.20.8/bin/X      424MiB |\r\n",
      "|    0   N/A  N/A      1455      G   ...nt-system/sw/bin/kwin_x11      124MiB |\r\n",
      "|    0   N/A  N/A      1483      G   ...ce-5.18.5/bin/plasmashell       65MiB |\r\n",
      "|    0   N/A  N/A      1700      G   ...AAAAAAAAA= --shared-files      329MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything works\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Packages we need\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Callable, Optional\n",
    "\n",
    "\n",
    "## For Reproducibility\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(42)\n",
    "\n",
    "## Tokenizer\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)\n",
    "\n",
    "## Device Configuration \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Everything works\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_dir = './data/flickr30k_images'\n",
    "image_dir = f'{data_dir}/flickr30k_images'\n",
    "csv_file = f'{data_dir}/results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_0</th>\n",
       "      <th>comment_1</th>\n",
       "      <th>comment_2</th>\n",
       "      <th>comment_3</th>\n",
       "      <th>comment_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/flickr30k_images/flickr30k_images/10000...</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/flickr30k_images/flickr30k_images/10002...</td>\n",
       "      <td>Several men in hard hats are operating a gian...</td>\n",
       "      <td>Workers look down from up above on a piece of...</td>\n",
       "      <td>Two men working on a machine wearing hard hats .</td>\n",
       "      <td>Four men on top of a tall structure .</td>\n",
       "      <td>Three men on a large rig .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/flickr30k_images/flickr30k_images/10002...</td>\n",
       "      <td>A child in a pink dress is climbing up a set ...</td>\n",
       "      <td>A little girl in a pink dress going into a wo...</td>\n",
       "      <td>A little girl climbing the stairs to her play...</td>\n",
       "      <td>A little girl climbing into a wooden playhouse</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/flickr30k_images/flickr30k_images/10003...</td>\n",
       "      <td>Someone in a blue shirt and hat is standing o...</td>\n",
       "      <td>A man in a blue shirt is standing on a ladder...</td>\n",
       "      <td>A man on a ladder cleans the window of a tall...</td>\n",
       "      <td>man in blue shirt and jeans on ladder cleanin...</td>\n",
       "      <td>a man on a ladder cleans a window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/flickr30k_images/flickr30k_images/10003...</td>\n",
       "      <td>Two men , one in a gray shirt , one in a blac...</td>\n",
       "      <td>Two guy cooking and joking around with the ca...</td>\n",
       "      <td>Two men in a kitchen cooking food on a stove .</td>\n",
       "      <td>Two men are at the stove preparing food .</td>\n",
       "      <td>Two men are cooking a meal .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  \\\n",
       "0  ./data/flickr30k_images/flickr30k_images/10000...   \n",
       "1  ./data/flickr30k_images/flickr30k_images/10002...   \n",
       "2  ./data/flickr30k_images/flickr30k_images/10002...   \n",
       "3  ./data/flickr30k_images/flickr30k_images/10003...   \n",
       "4  ./data/flickr30k_images/flickr30k_images/10003...   \n",
       "\n",
       "                                           comment_0  \\\n",
       "0   Two young guys with shaggy hair look at their...   \n",
       "1   Several men in hard hats are operating a gian...   \n",
       "2   A child in a pink dress is climbing up a set ...   \n",
       "3   Someone in a blue shirt and hat is standing o...   \n",
       "4   Two men , one in a gray shirt , one in a blac...   \n",
       "\n",
       "                                           comment_1  \\\n",
       "0   Two young , White males are outside near many...   \n",
       "1   Workers look down from up above on a piece of...   \n",
       "2   A little girl in a pink dress going into a wo...   \n",
       "3   A man in a blue shirt is standing on a ladder...   \n",
       "4   Two guy cooking and joking around with the ca...   \n",
       "\n",
       "                                           comment_2  \\\n",
       "0   Two men in green shirts are standing in a yard .   \n",
       "1   Two men working on a machine wearing hard hats .   \n",
       "2   A little girl climbing the stairs to her play...   \n",
       "3   A man on a ladder cleans the window of a tall...   \n",
       "4     Two men in a kitchen cooking food on a stove .   \n",
       "\n",
       "                                           comment_3  \\\n",
       "0       A man in a blue shirt standing in a garden .   \n",
       "1              Four men on top of a tall structure .   \n",
       "2    A little girl climbing into a wooden playhouse    \n",
       "3   man in blue shirt and jeans on ladder cleanin...   \n",
       "4          Two men are at the stove preparing food .   \n",
       "\n",
       "                                  comment_4  \n",
       "0   Two friends enjoy time spent together .  \n",
       "1                Three men on a large rig .  \n",
       "2     A girl going into a wooden building .  \n",
       "3         a man on a ladder cleans a window  \n",
       "4              Two men are cooking a meal .  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's an error on line 19999 of this dataset, I had to search this up to fix it\n",
    "df = pd.read_csv(csv_file, delimiter='|')\n",
    "df[' comment_number'][19999] = ' 4'\n",
    "df[' comment'][19999] = ' A dog runs across the grass .'\n",
    "df['image_name'] = image_dir+'/'+df['image_name']\n",
    "df.head(5)\n",
    "\n",
    "# Sort the data into a data frame with 4 comment cells on each row\n",
    "image_name = {\n",
    "    'image_name':df[df[' comment_number'] == df[' comment_number'][0]]['image_name'].values,\n",
    "}\n",
    "comments = {\n",
    "    'comment_0':df[df[' comment_number'] == df[' comment_number'][0]][' comment'].values,\n",
    "    'comment_1':df[df[' comment_number'] == df[' comment_number'][1]][' comment'].values,\n",
    "    'comment_2':df[df[' comment_number'] == df[' comment_number'][2]][' comment'].values,\n",
    "    'comment_3':df[df[' comment_number'] == df[' comment_number'][3]][' comment'].values,\n",
    "    'comment_4':df[df[' comment_number'] == df[' comment_number'][4]][' comment'].values,\n",
    "}\n",
    "\n",
    "image_name_df = pd.DataFrame.from_dict(image_name)\n",
    "comments_df = pd.DataFrame.from_dict(comments)\n",
    "\n",
    "df = pd.concat([image_name_df,comments_df], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19069, 6)\n",
      "(6357, 6)\n",
      "(6357, 6)\n"
     ]
    }
   ],
   "source": [
    "## Training and Test splits \n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "## Reset Indexes \n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "## Split training into training and validation \n",
    "train, val = train_test_split(train, test_size=0.25, random_state=42)\n",
    "\n",
    "## Reset Indexes \n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "\n",
    "## Get sizes\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlickrDataset(Dataset):\n",
    "    def __init__(self, data, \n",
    "                 transforms: Optional[Callable] = None) -> None:\n",
    "        self.data = data\n",
    "        self.transforms = T.Compose([\n",
    "            T.Resize((256,256)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = [0.5], std = [0.5]),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i: int):\n",
    "        image_name = self.data.image_name.values[i]\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        comments = self.data[self.data.image_name == image_name].values.tolist()[0][1:][0]\n",
    "        encoded_inputs = tokenizer(comments,\n",
    "                            return_token_type_ids = False, \n",
    "                            return_attention_mask = False, \n",
    "                            max_length = 100, \n",
    "                            padding = \"max_length\",\n",
    "                            return_tensors = \"pt\")\n",
    "        \n",
    "        sample = {\"image\":image.to(device),\n",
    "                  \"captions\": encoded_inputs[\"input_ids\"].flatten().to(device)}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[ 0.1216,  0.2784,  0.3569,  ..., -0.0980, -0.0196, -0.0431],\n",
       "          [ 0.0745,  0.0667,  0.0902,  ...,  0.0980,  0.2078,  0.2314],\n",
       "          [ 0.2941,  0.3412,  0.4118,  ...,  0.1059,  0.1451,  0.2157],\n",
       "          ...,\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.4510,  0.5490,  0.5804,  ...,  0.3961,  0.3961,  0.3882],\n",
       "          [ 0.4549,  0.4000,  0.3647,  ...,  0.4471,  0.5255,  0.4902],\n",
       "          [ 0.6196,  0.6431,  0.6667,  ...,  0.4627,  0.5059,  0.4902],\n",
       "          ...,\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.4588,  0.5961,  0.6471,  ...,  0.4235,  0.4353,  0.4078],\n",
       "          [ 0.4275,  0.4157,  0.4078,  ...,  0.4745,  0.5333,  0.4863],\n",
       "          [ 0.6157,  0.6275,  0.6353,  ...,  0.4824,  0.5529,  0.5176],\n",
       "          ...,\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       "        device='cuda:0'),\n",
       " 'captions': tensor([  101,  2177,  1997,  2111,  3061,  2006,  1037,  4586,  3139,  2598,\n",
       "          1010,  2070,  2024,  3173, 23528,  2015,  1010,  2045,  2003,  1037,\n",
       "          3899,  2007,  1996,  2177,  1012,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = FlickrDataset(train, transforms = True)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, drop_last=True)\n",
    "\n",
    "val_dataset = FlickrDataset(val, transforms = True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size,drop_last=True)\n",
    "\n",
    "test_dataset = FlickrDataset(test, transforms = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size,drop_last=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
